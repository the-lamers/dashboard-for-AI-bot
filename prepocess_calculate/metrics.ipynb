{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZRJxpxaSfaD"
      },
      "source": [
        "Математическая модель метрики галлюцинации, реализованная в коде, выглядит следующим образом:\n",
        "\n",
        "# Обозначения:\n",
        "\n",
        "- $S_{h}$ — итоговый **hallucination score** (метрика галлюцинации).\n",
        "- $S_c$ — **concept score** (концептуальная согласованность), вычисляемая через **косинусное сходство** между эмбеддингами ответа модели и контекста.\n",
        "- $F_h$ — количество **галлюцинированных фактов** (факты в ответе модели, которых нет в контексте).\n",
        "- $F_m$ — количество **пропущенных фактов** (факты, присутствующие в контексте, но отсутствующие в ответе модели).\n",
        "- $F_{total}$ — общее число фактов в ответе модели.\n",
        "- $w_c$ = 0.4 — вес концептуальной согласованности.\n",
        "- $w_f$ = 0.6 — вес фактологической ошибки.\n",
        "---\n",
        "\n",
        "## 1. Концептуальная согласованность\n",
        "\n",
        "$\n",
        "S_c = \\cos(\\theta) = \\frac{V_{model} \\cdot V_{context}}{|V_{model}| |V_{context}|}\n",
        "$\n",
        "\n",
        "где \\( $V_{model}$ \\) и \\( $V_{context}$ \\) — это BERT-эмбеддинги CLS-токенов.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Доля фактологических ошибок\n",
        "$\n",
        "E_f =\n",
        "\\begin{cases}\n",
        "1, & \\text{если } F_{total} = 0 \\text{ и } |F_m| > 0 \\\\\n",
        "0, & \\text{если } F_{total} = 0 \\text{ и } |F_m| = 0 \\\\\n",
        "\\frac{|F_h| + |F_m|}{F_{total}}, & \\text{иначе}\n",
        "\\end{cases}$\n",
        "\n",
        "где $E_f$ — **fact error ratio** (доля ошибок в фактах).\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Итоговая метрика галлюцинации\n",
        "$\n",
        "S_h = w_c (1 - S_c) + w_f E_f\n",
        "$\n",
        "\n",
        "где:\n",
        "\n",
        "- Чем выше $S_h$, тем больше модель галлюцинирует.\n",
        "- Чем ниже $S_h$, тем качественнее ответ модели.\n",
        "- $S_h$ нормализуется в пределах $[0, 1]$:\n",
        "\n",
        "$\n",
        "S_h = \\min(1, \\max(0, S_h))\n",
        "$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtfbTFVVvAmP",
        "outputId": "9f4153cd-1686-4241-8b34-1f9153a252c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.3.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.13)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04glbWtOu4J-",
        "outputId": "d28a030d-f626-4f35-ead7-8dfbb630e4fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример 1 (противоречие в годе):\n",
            "Метрика галлюцинации: 0.633\n",
            "Количество противоречий: 2\n",
            "Количество пропущенных фактов: 3\n",
            "Доля противоречий: 0.667\n",
            "Штраф за пропущенные факты: 0.500\n",
            "Интерпретация: Скорее галлюцинация\n",
            "\n",
            "Пример 2 (нет противоречий):\n",
            "Метрика галлюцинации: 0.900\n",
            "Количество противоречий: 1\n",
            "Количество пропущенных фактов: 5\n",
            "Доля противоречий: 1.000\n",
            "Штраф за пропущенные факты: 0.500\n",
            "Интерпретация: Галлюцинация\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import re\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "class FactVerificationScore:\n",
        "    def __init__(self, model_name='bert-base-cased'):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "        self.model = BertModel.from_pretrained(model_name)\n",
        "        self.model.eval()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def _encode_text(self, text):\n",
        "        \"\"\"Кодирует текст в эмбеддинги с помощью BERT (используется только при необходимости)\"\"\"\n",
        "        inputs = self.tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # CLS-токен\n",
        "        return embeddings\n",
        "\n",
        "    def _extract_facts(self, text):\n",
        "        \"\"\"Извлекает факты: числа, даты, имена собственные, включая сокращения\"\"\"\n",
        "        patterns = [\n",
        "            r'\\b(?:НИУ )?ВШЭ\\b',  # ВШЭ или НИУ ВШЭ\n",
        "            r'\\b\\d{4}\\b',          # Годы\n",
        "            r'[А-ЯA-Z][а-яa-z]+(?: [А-ЯA-Z][а-яa-z]+)*'  # Имена собственные\n",
        "        ]\n",
        "        facts = set()\n",
        "        for pattern in patterns:\n",
        "            facts.update(re.findall(pattern, text))\n",
        "        return facts\n",
        "\n",
        "    def _check_contradictions(self, model_facts, context_facts):\n",
        "        \"\"\"Проверяет наличие противоречий между фактами\"\"\"\n",
        "        contradictions = 0\n",
        "        for model_fact in model_facts:\n",
        "            if model_fact in context_facts:\n",
        "                continue  # Факт совпадает, не противоречие\n",
        "            # Если факт из model_output — год, а в context есть другой год\n",
        "            if re.match(r'\\b\\d{4}\\b', model_fact):\n",
        "                context_years = {f for f in context_facts if re.match(r'\\b\\d{4}\\b', f)}\n",
        "                if context_years and model_fact not in context_years:\n",
        "                    contradictions += 1\n",
        "            # Если это сущность (не год), и её нет в контексте — считаем потенциальным противоречием\n",
        "            elif model_fact not in context_facts:\n",
        "                contradictions += 1\n",
        "        return contradictions\n",
        "\n",
        "    def calculate_score(self, model_output, context):\n",
        "        # 1. Извлечение фактов\n",
        "        model_facts = self._extract_facts(model_output)\n",
        "        context_facts = self._extract_facts(context)\n",
        "\n",
        "        # 2. Проверка противоречий\n",
        "        contradictions = self._check_contradictions(model_facts, context_facts)\n",
        "\n",
        "        # 3. Оценка пропущенных фактов (менее критична, чем противоречия)\n",
        "        missing_facts = len(context_facts - model_facts)\n",
        "\n",
        "        # 4. Расчет метрики\n",
        "        total_model_facts = len(model_facts) if len(model_facts) > 0 else 1  # Избегаем деления на 0\n",
        "        contradiction_ratio = contradictions / total_model_facts  # Доля противоречий\n",
        "        missing_fact_penalty = min(0.5, missing_facts / (len(context_facts) + 1))  # Штраф за пропуски, ограничен 0.5\n",
        "\n",
        "        # Итоговая метрика: больше вес у противоречий, меньше у пропущенных фактов\n",
        "        w_contradiction = 0.8  # Высокий вес для противоречий\n",
        "        w_missing = 0.2        # Низкий вес для пропущенных фактов\n",
        "\n",
        "        hallucination_score = (\n",
        "            w_contradiction * contradiction_ratio +\n",
        "            w_missing * missing_fact_penalty\n",
        "        )\n",
        "        hallucination_score = min(1.0, max(0.0, hallucination_score))  # Ограничение [0, 1]\n",
        "\n",
        "        # Интерпретация результата\n",
        "        interpretation = (\n",
        "            \"Корректный ответ\" if hallucination_score < 0.3 else\n",
        "            \"Скорее корректный\" if hallucination_score < 0.5 else\n",
        "            \"Скорее галлюцинация\" if hallucination_score < 0.7 else\n",
        "            \"Галлюцинация\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"hallucination_score\": hallucination_score,\n",
        "            \"contradictions\": contradictions,\n",
        "            \"missing_facts\": missing_facts,\n",
        "            \"contradiction_ratio\": contradiction_ratio,\n",
        "            \"missing_fact_penalty\": missing_fact_penalty,\n",
        "            \"interpretation\": interpretation\n",
        "        }\n",
        "\n",
        "# Пример использования\n",
        "if __name__ == \"__main__\":\n",
        "    evaluator = FactVerificationScore()\n",
        "\n",
        "    # Пример 1: Противоречие в годе\n",
        "    model_output = \"ВШЭ - это крупнейший университет России, основанный в 1990 году.\"\n",
        "    context = \"НИУ ВШЭ был основан в 1992 году. Высшая школа экономики является одним из ведущих университетов России.\"\n",
        "    result = evaluator.calculate_score(model_output, context)\n",
        "    print(\"Пример 1 (противоречие в годе):\")\n",
        "    print(f\"Метрика галлюцинации: {result['hallucination_score']:.3f}\")\n",
        "    print(f\"Количество противоречий: {result['contradictions']}\")\n",
        "    print(f\"Количество пропущенных фактов: {result['missing_facts']}\")\n",
        "    print(f\"Доля противоречий: {result['contradiction_ratio']:.3f}\")\n",
        "    print(f\"Штраф за пропущенные факты: {result['missing_fact_penalty']:.3f}\")\n",
        "    print(f\"Интерпретация: {result['interpretation']}\\n\")\n",
        "\n",
        "    # Пример 2: Нет противоречий\n",
        "    model_output_1 = \"Для получения социальной стипендии необходимо подать заявку через сервис единого окна в модуле LMS, прикрепив отсканированные документы (личное заявление и документ, подтверждающий льготу).\"\n",
        "    context_1 = \"Дополнительные документы для получения социальной стипендии нужно предоставить в Центр стипендиальных и благотворительных программ НИУ ВШЭ или через сервис единого окна в модуле LMS. Это включает копию заявления и копию действующей справки МСЭ.\\\n",
        "    Также Для получения социальной стипендии необходимо подать заявку через сервис единого окна в модуле LMS, прикрепив отсканированные документы (личное заявление и документ, подтверждающий льготу)\"\n",
        "    result = evaluator.calculate_score(model_output_1, context_1)\n",
        "    print(\"Пример 2 (нет противоречий):\")\n",
        "    print(f\"Метрика галлюцинации: {result['hallucination_score']:.3f}\")\n",
        "    print(f\"Количество противоречий: {result['contradictions']}\")\n",
        "    print(f\"Количество пропущенных фактов: {result['missing_facts']}\")\n",
        "    print(f\"Доля противоречий: {result['contradiction_ratio']:.3f}\")\n",
        "    print(f\"Штраф за пропущенные факты: {result['missing_fact_penalty']:.3f}\")\n",
        "    print(f\"Интерпретация: {result['interpretation']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx5BmwKL3Ktb",
        "outputId": "d496c5f4-751a-48c5-af86-d0c441d2f4cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXfwCN08281W",
        "outputId": "1a7d9d41-628f-4314-e30e-8dd04fad1736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score для хорошего ответа: 0.2147\n",
            "Score для плохого ответа: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.translate import bleu_score\n",
        "nltk.download('punkt')\n",
        "\n",
        "def hallucination_score(contexts: List[str], model_output: str) -> float:\n",
        "    \"\"\"\n",
        "    Оценивает потенциальные галлюцинации в ответе LLM, сравнивая его с набором контекстов.\n",
        "    Использует BLEU (precision) для измерения n-граммного соответствия между model_output и contexts.\n",
        "\n",
        "    Args:\n",
        "        contexts (List[str]): Список строк контекста, на основе которых модель должна была генерировать ответ.\n",
        "        model_output (str): Ответ, сгенерированный LLM, который нужно проверить.\n",
        "\n",
        "    Returns:\n",
        "        float: Средний BLEU-score (precision для биграмм) по всем контекстам.\n",
        "               Низкое значение (<0.3) может указывать на галлюцинацию.\n",
        "    \"\"\"\n",
        "    bleu_scores = []\n",
        "\n",
        "    # Проходим по каждому контексту\n",
        "    for context in contexts:\n",
        "        try:\n",
        "            # Вычисляем BLEU с учетом биграмм (max_order=2)\n",
        "            score = bleu_score.sentence_bleu(\n",
        "                references=[context.split()],  # Разбиваем контекст на токены\n",
        "                hypothesis=model_output.split(),  # Разбиваем ответ модели на токены\n",
        "                weights=(0, 1, 0, 0)  # Используем только биграммы (precision2)\n",
        "            )\n",
        "            bleu_scores.append(score)\n",
        "        except ZeroDivisionError:\n",
        "            # Если деление на ноль (например, пустой контекст или ответ), добавляем 0\n",
        "            bleu_scores.append(0)\n",
        "\n",
        "    # Возвращаем среднее значение BLEU по всем контекстам\n",
        "    return np.mean(bleu_scores) if bleu_scores else 0.0\n",
        "\n",
        "# Пример использования\n",
        "if __name__ == \"__main__\":\n",
        "    # Пример данных\n",
        "    contexts = [\n",
        "        \"Для оформления материальной помощи на оплату общежития необходимо предоставить определенные медицинские документы, такие как справка по форме 086у или сертификат МОДФ.\",\n",
        "        \"Также нужно учесть, что условия предоставления мест и размещения в общежитиях различаются.\"\n",
        "         \"Более подробную информацию можно получить в Дирекции по управлению общежитиями, гостиницами, учебно-оздоровительными комплексами.\"\n",
        "    ]\n",
        "    model_output_good = \"Для оформления материальной помощи на оплату общежития необходимо предоставить определенные медицинские документы\"\n",
        "    model_output_bad = \"Интернет изобрел Илон Маск в 2010 году в гараже.\"\n",
        "\n",
        "    # Проверка хорошего ответа\n",
        "    good_score = hallucination_score(contexts, model_output_good)\n",
        "    print(f\"Score для хорошего ответа: {good_score:.4f}\")\n",
        "\n",
        "    # Проверка плохого (галлюцинирующего) ответа\n",
        "    bad_score = hallucination_score(contexts, model_output_bad)\n",
        "    print(f\"Score для плохого ответа: {bad_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLW01E_65egj"
      },
      "source": [
        "3. Анализ ключевых слов\n",
        "Идея: Извлечь ключевые слова из contexts и проверить их присутствие в model_output. Отсутствие важных терминов может указывать на отклонение от темы.\n",
        "\n",
        "Реализация:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "z7eah-G65D8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20e904b-3304-45c3-deea-74d639176a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from collections import Counter\n",
        "\n",
        "def extract_keywords(text: str, stop_words) -> set:\n",
        "    words = text.lower().split()\n",
        "    return {word for word in words if word not in stop_words and len(word) > 3}\n",
        "\n",
        "def hallucination_score(contexts: List[str], model_output: str) -> float:\n",
        "    bleu_scores = []\n",
        "    stop_words = set(stopwords.words('russian'))  # Для русского языка\n",
        "\n",
        "    # Извлекаем ключевые слова из всех контекстов\n",
        "    context_keywords = set()\n",
        "    for context in contexts:\n",
        "        context_keywords.update(extract_keywords(context, stop_words))\n",
        "\n",
        "    # Ключевые слова из model_output\n",
        "    output_keywords = extract_keywords(model_output, stop_words)\n",
        "\n",
        "    # Доля пересечения ключевых слов\n",
        "    keyword_overlap = len(context_keywords & output_keywords) / len(context_keywords) if context_keywords else 0.0\n",
        "\n",
        "    for context in contexts:\n",
        "        try:\n",
        "            score = bleu_score.sentence_bleu(\n",
        "                references=[context.split()],\n",
        "                hypothesis=model_output.split(),\n",
        "                weights=(0, 1, 0, 0)\n",
        "            )\n",
        "            bleu_scores.append(score)\n",
        "        except ZeroDivisionError:\n",
        "            bleu_scores.append(0)\n",
        "\n",
        "    bleu_mean = np.mean(bleu_scores) if bleu_scores else 0.0\n",
        "\n",
        "    # Комбинируем BLEU и пересечение ключевых слов\n",
        "    return 0.7 * bleu_mean + 0.3 * keyword_overlap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Самая лучшая\n",
        "---\n",
        "### Математическая модель метрики \"степень галлюцинации\"\n",
        "\n",
        "#### Входные данные:\n",
        "- $C$ = ${c_1, c_2, ..., c_n}$ — список контекстов (строк), где $n$ — количество контекстов.\n",
        "- $O$ — строка, представляющая вывод модели (ответ).\n",
        "- $S$ — множество стоп-слов (на русском языке).\n",
        "\n",
        "#### Шаг 1: Извлечение ключевых слов\n",
        "Для каждой строки $x$ (контекста или вывода модели) определяется множество ключевых слов:\n",
        "$$\n",
        "K(x) = \\{ w \\mid w \\in x.split(), w \\notin S, len(w) > 3 \\}\n",
        "$$\n",
        "- $w$ — слово в нижнем регистре.\n",
        "- Условие $$w \\notin S$$ исключает стоп-слова.\n",
        "- Условие $len(w) > 3$ исключает короткие слова.\n",
        "\n",
        "Множества ключевых слов:\n",
        "- $K_C = \\bigcup_{i=1}^n K(c_i)$ — объединение ключевых слов всех контекстов.\n",
        "- $K_O = K(O)$ — ключевые слова из вывода модели.\n",
        "\n",
        "#### Шаг 2: Jaccard-подобная схожесть ключевых слов\n",
        "Схожесть между контекстом и выводом по ключевым словам вычисляется как:\n",
        "$$\n",
        "J = \\frac{|K_C \\cap K_O|}{\\max(|K_O|, 1)}\n",
        "$$\n",
        "- $|K_C \\cap K_O|$ — количество общих ключевых слов.\n",
        "- $max(|K_O|, 1)$ — нормализация по количеству слов в выводе (избегаем деления на 0).\n",
        "- Это отражает долю пересечения ключевых слов, избегая чрезмерного штрафа за краткость ответа.\n",
        "\n",
        "#### Шаг 3: BLEU-оценка\n",
        "Для каждого контекста $c_i$ вычисляется BLEU-оценка между $c_i$ и $O$:\n",
        "$$\n",
        "B_i = BLEU(c_i.split(), O.split(), w)\n",
        "$$\n",
        "- $w = (0.7, 0.3, 0, 0)$ — веса для униграмм $(70%)$ и биграмм $(30%)$, триграммы и выше не учитываются.\n",
        "- Если возникает $ZeroDivisionError,B_i = 0$.\n",
        "\n",
        "Средняя BLEU-оценка по всем контекстам:\n",
        "$\n",
        "B = \\frac{1}{n} \\sum_{i=1}^n B_i \\quad \\text{(или 0, если } n = 0\\text{)}\n",
        "$\n",
        "\n",
        "#### Шаг 4: Штраф за неожиданные слова\n",
        "Неожиданные слова — это слова в выводе, отсутствующие в контексте:\n",
        "$\n",
        "U = K_O \\setminus K_C\n",
        "$\n",
        "Штраф за неожиданные слова:\n",
        "$$\n",
        "P = \\begin{cases}\n",
        "\\frac{|U|}{|K_O| + \\epsilon} & \\text{если } U \\neq \\emptyset, \\\\\n",
        "0 & \\text{если } U = \\emptyset,\n",
        "\\end{cases}\n",
        "$$\n",
        "- $epsilon = 10^{-6}$ — малая константа для избежания деления на 0.\n",
        "- Штраф пропорционален доле неожиданных слов в выводе.\n",
        "\n",
        "#### Шаг 5: Итоговый коэффициент\n",
        "Итоговая метрика \"степень галлюцинации\" (точнее, степень правдоподобности) вычисляется как:\n",
        "$\n",
        "H = \\left( 0.6 \\cdot B + 0.4 \\cdot J \\right) \\cdot (1 - P)\n",
        "$\n",
        "- $0.6 \\cdot B$ — вклад BLEU-оценки (60%).\n",
        "- $0.4 \\cdot J$ — вклад пересечения ключевых слов (40%).\n",
        "- $(1 - P)$ — множитель, уменьшающий итоговую оценку при наличии неожиданных слов.\n",
        "\n",
        "Ограничение на отрицательные значения:\n",
        "$\n",
        "H_{final} = \\max(H, 0)\n",
        "$\n",
        "\n",
        "---\n",
        "\n",
        "### Интерпретация\n",
        "- $H_{final} \\in [0, 1]$:\n",
        "  - $H_{final} \\approx 1$: Вывод модели полностью соответствует контексту (высокий BLEU, большое пересечение ключевых слов, нет неожиданных слов).\n",
        "  - $H_{final} \\approx 0$: Вывод модели сильно отклоняется от контекста (низкий BLEU, мало общих слов, много неожиданных слов).\n",
        "- Чем выше $H_{final}$, тем меньше \"галлюцинаций\" в ответе.\n",
        "\n",
        "---\n",
        "\n",
        "### Пример\n",
        "#### Вход:\n",
        "- $C = [\"Москва - столица России\"]$\n",
        "- $O = \"Москва - большой город\"$\n",
        "- $S = \\{\"и\", \"в\", \"на\"\\}$ (упрощённый набор стоп-слов)\n",
        "\n",
        "#### Вычисления:\n",
        "\n",
        "$$\n",
        "1. K_C = { \"москва\", \"столица\", \"россии\" }\n",
        "$$$$\n",
        "2. K_O = { \"москва\", \"большой\", \"город\"}\n",
        "$$$$\n",
        "3. J = \\frac{|\\{ \"москва\" \\}|}{\\max(3, 1)} = \\frac{1}{3} \\approx 0.333)\n",
        "$$$$\n",
        "4. B —  BLEU-оценка между \"москва столица россии\" и \"москва большой город\" (допустим, ( B \\approx 0.4 )).\n",
        "$$$$\n",
        "5. U = { \"большой\", \"город\" },  ( P = \\frac{2}{3 + 10^{-6}} \\approx 0.667 )\n",
        "$$$$\n",
        "6. (H = (0.6 \\cdot 0.4 + 0.4 \\cdot 0.333) \\cdot (1 - 0.667) = (0.24 + 0.133) \\cdot 0.333 \\approx 0.373 \\cdot 0.333 \\approx 0.124)\n",
        "$$$$\n",
        "7. H_{final} = 0.124\n",
        "$$\n",
        "#### Результат:\n",
        "$H_{final} = 0.124$ — низкий показатель, указывающий на наличие галлюцинаций (\"большой город\" не из контекста)."
      ],
      "metadata": {
        "id": "G4sv3lHhHwzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk numpy scikit-learn sentence-transformers"
      ],
      "metadata": {
        "id": "KLWyjs5BP-c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.translate import bleu_score\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from typing import List\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def extract_keywords(text: str, stop_words) -> set:\n",
        "    \"\"\"Извлекает ключевые слова, исключая стоп-слова и короткие токены.\"\"\"\n",
        "    words = text.lower().split()\n",
        "    return {word for word in words if word not in stop_words and len(word) > 3}\n",
        "\n",
        "def hallucination_score(contexts: List[str], model_output: str) -> float:\n",
        "    \"\"\"Оценивает степень галлюцинации ответа модели по сравнению с контекстом.\"\"\"\n",
        "\n",
        "    stop_words = set(stopwords.words('russian'))  # Стоп-слова для русского языка\n",
        "\n",
        "    # Извлекаем ключевые слова из всех контекстов\n",
        "    context_keywords = set()\n",
        "    for context in contexts:\n",
        "        context_keywords.update(extract_keywords(context, stop_words))\n",
        "\n",
        "    # Ключевые слова из ответа модели\n",
        "    output_keywords = extract_keywords(model_output, stop_words)\n",
        "\n",
        "    # Jaccard similarity (не штрафуем, если ответ короче, но точен)\n",
        "    keyword_overlap = len(context_keywords & output_keywords) / max(len(output_keywords), 1)\n",
        "\n",
        "    # BLEU-оценка (с униграммами и биграммами)\n",
        "    bleu_scores = []\n",
        "    for context in contexts:\n",
        "        try:\n",
        "            score = bleu_score.sentence_bleu(\n",
        "                references=[context.split()],\n",
        "                hypothesis=model_output.split(),\n",
        "                weights=(0.7, 0.3, 0, 0)  # Униграммы (70%) и биграммы (30%)\n",
        "            )\n",
        "            bleu_scores.append(score)\n",
        "        except ZeroDivisionError:\n",
        "            bleu_scores.append(0)\n",
        "\n",
        "    bleu_mean = np.mean(bleu_scores) if bleu_scores else 0.0\n",
        "\n",
        "    # Штраф за неожиданные слова (только если они действительно выбиваются из контекста)\n",
        "    unexpected_words = output_keywords - context_keywords\n",
        "    if unexpected_words:\n",
        "        unexpected_penalty = len(unexpected_words) / (len(output_keywords) + 1e-6)\n",
        "    else:\n",
        "        unexpected_penalty = 0  # Если нет неожиданных слов, штрафа нет\n",
        "\n",
        "    # Итоговый коэффициент (BLEU + семантическое пересечение - штраф за ошибки)\n",
        "    final_score = (0.6 * bleu_mean + 0.4 * keyword_overlap) * (1 - unexpected_penalty)\n",
        "\n",
        "    return max(final_score, 0)  # Исключаем отрицательные значения\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFLtQQTOF3XM",
        "outputId": "8df0a0d3-f58c-4f93-e750-ba4052840c65"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот код предназначен для оценки степени галлюцинации (т. е. отклонения ответа модели от контекста). Он использует несколько методов анализа текста:\n",
        "\n",
        "1. Извлечение ключевых слов (extract_keywords)\n",
        "Использует nltk.word_tokenize для разбиения текста на токены.\n",
        "Исключает стоп-слова (stopwords.words('russian')).\n",
        "Учитывает только слова длиной > 3 символов.\n",
        "Возвращает Counter, содержащий частоту появления слов.\n",
        "2. Косинусная схожесть (cosine_similarity)\n",
        "Вычисляет сходство между двумя наборами ключевых слов, представляя их в виде векторных представлений.\n",
        "Использует скалярное произведение и нормализацию, чтобы получить коэффициент от 0 до 1.\n",
        "3. Семантическая схожесть (semantic_similarity)\n",
        "Преобразует контексты и ответ модели в векторные представления с помощью SentenceTransformer (distiluse-base-multilingual-cased).\n",
        "Вычисляет среднюю косинусную схожесть между векторами контекстов и вектором ответа.\n",
        "4. BLEU-оценка (bleu_score)\n",
        "Оценивает совпадение между model_output и каждым контекстом на уровне n-грамм.\n",
        "Использует веса (0,5 для униграмм, 0,3 для биграмм, 0,2 для триграмм), чтобы учитывать разные уровни совпадений.\n",
        "5. Штраф за неожиданные слова\n",
        "Определяет слова, которые есть в ответе, но отсутствуют в контексте.\n",
        "Увеличивает штраф до 0,8, если таких слов слишком много.\n",
        "\n",
        "Этот метод комплексно оценивает галлюцинации, балансируя между точностью (BLEU), смысловым соответствием (SentenceTransformer) и лексическим пересечением (ключевые слова). Если ответ сильно отклоняется от контекста, он получит низкий балл, а если близок к контексту — высокий."
      ],
      "metadata": {
        "id": "5J7hjzERQYqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.translate import bleu_score\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from typing import List\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Используем предобученную модель для семантического сравнения\n",
        "model = SentenceTransformer('distiluse-base-multilingual-cased')\n",
        "\n",
        "def extract_keywords(text: str, stop_words) -> Counter:\n",
        "    \"\"\"Извлекает ключевые слова и их частоту.\"\"\"\n",
        "    words = [word for word in nltk.word_tokenize(text.lower()) if word not in stop_words and len(word) > 3]\n",
        "    return Counter(words)\n",
        "\n",
        "def cosine_similarity(counter1: Counter, counter2: Counter) -> float:\n",
        "    \"\"\"Взвешенная косинусная схожесть между двумя наборами ключевых слов.\"\"\"\n",
        "    all_words = set(counter1.keys()).union(counter2.keys())\n",
        "    if not all_words:\n",
        "        return 0.0\n",
        "\n",
        "    vec1 = np.array([counter1[word] for word in all_words])\n",
        "    vec2 = np.array([counter2[word] for word in all_words])\n",
        "\n",
        "    norm1 = np.linalg.norm(vec1) + 1e-6\n",
        "    norm2 = np.linalg.norm(vec2) + 1e-6\n",
        "\n",
        "    return np.dot(vec1, vec2) / (norm1 * norm2)\n",
        "\n",
        "def semantic_similarity(contexts: List[str], model_output: str) -> float:\n",
        "    \"\"\"Оценка семантической схожести с использованием SentenceTransformer.\"\"\"\n",
        "    context_embeddings = model.encode(contexts, convert_to_tensor=True)\n",
        "    output_embedding = model.encode(model_output, convert_to_tensor=True)\n",
        "    similarity_scores = util.pytorch_cos_sim(context_embeddings, output_embedding)\n",
        "    return max(similarity_scores.mean().item(), 0.0)\n",
        "\n",
        "def hallucination_score(contexts: List[str], model_output: str) -> float:\n",
        "    \"\"\"Оценка галлюцинации с учётом семантической близости и неожиданных слов.\"\"\"\n",
        "    stop_words = set(stopwords.words('russian'))\n",
        "\n",
        "    # Объединяем все контексты и извлекаем ключевые слова\n",
        "    context_text = \" \".join(contexts)\n",
        "    context_keywords = extract_keywords(context_text, stop_words)\n",
        "    output_keywords = extract_keywords(model_output, stop_words)\n",
        "\n",
        "    # Косинусная схожесть\n",
        "    keyword_similarity = cosine_similarity(context_keywords, output_keywords)\n",
        "\n",
        "    # Семантическая схожесть с SentenceTransformer\n",
        "    semantic_score = semantic_similarity(contexts, model_output)\n",
        "\n",
        "    # BLEU-оценка\n",
        "    bleu_scores = []\n",
        "    for context in contexts:\n",
        "        try:\n",
        "            score = bleu_score.sentence_bleu(\n",
        "                references=[nltk.word_tokenize(context.lower())],\n",
        "                hypothesis=nltk.word_tokenize(model_output.lower()),\n",
        "                weights=(0.5, 0.3, 0.2, 0)  # Униграммы (50%), биграммы (30%), триграммы (20%)\n",
        "            )\n",
        "            bleu_scores.append(score)\n",
        "        except:\n",
        "            bleu_scores.append(0)\n",
        "    bleu_mean = np.mean(bleu_scores) if bleu_scores else 0.0\n",
        "\n",
        "    # Штраф за неожиданные слова (усиленный)\n",
        "    unexpected_words = output_keywords - context_keywords\n",
        "    unexpected_penalty = min(len(unexpected_words) / (len(output_keywords) + 1e-6), 0.8)  # Усиливаем штраф до 0.8\n",
        "\n",
        "    # Итоговый скор (BLEU + семантическая схожесть + ключевые слова - штраф за неожиданные слова)\n",
        "    final_score = (0.45 * bleu_mean + 0.25 * semantic_score + 0.3 * keyword_similarity) * (1 - unexpected_penalty)\n",
        "\n",
        "    print(f\"BLEU: {bleu_mean}, Semantic: {semantic_score}, Keyword Sim: {keyword_similarity}, Penalty: {unexpected_penalty}\")\n",
        "\n",
        "    return max(final_score, 0.0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaJGGdnCOVwD",
        "outputId": "789847e0-04fe-4951-db5d-f2c4661263c4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования\n",
        "if __name__ == \"__main__\":\n",
        "    # Пример данных\n",
        "    contexts = [\n",
        "        \"Для оформления материальной помощи на оплату общежития необходимо предоставить определенные медицинские документы, такие как справка по форме 086у или сертификат МОДФ.\",\n",
        "        \"Также нужно учесть, что условия предоставления мест и размещения в общежитиях различаются.\"\n",
        "         \"Более подробную информацию можно получить в Дирекции по управлению общежитиями, гостиницами, учебно-оздоровительными комплексами.\"\n",
        "    ]\n",
        "    model_output_good = \"Для оформления материальной помощи на оплату общежития необходимо предоставить определенные медицинские документы\"\n",
        "    model_output_bad = \"Интернет изобрел Илон Маск в 2010 году в гараже.\"\n",
        "\n",
        "    # Проверка хорошего ответа\n",
        "    good_score = hallucination_score(contexts, model_output_good)\n",
        "    print(f\"Score для хорошего ответа: {good_score:.4f}\")\n",
        "\n",
        "    # Проверка плохого (галлюцинирующего) ответа\n",
        "    bad_score = hallucination_score(contexts, model_output_bad)\n",
        "    print(f\"Score для плохого ответа: {bad_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90YIcJkNMf8T",
        "outputId": "153986ce-9ba3-4d4c-ff27-430fa5fd16b7"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score для хорошего ответа: 0.4406\n",
            "Score для плохого ответа: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number 3.\n",
        "# Пример 1\n",
        "model_output_1 = \"Для продления социальной стипендии необходимо подать заявку через сервис единого окна в модуле LMS, прикрепив отсканированные документы (личное заявление и документ, подтверждающий льготу).\"\n",
        "context_1 = [\"Дополнительные документы для продления социальной стипендии нужно предоставить в Центр стипендиальных и благотворительных программ НИУ ВШЭ. Это включает копию заявления и копию действующей справки МСЭ. Для продления социальной стипендии необходимо подать заявку через сервис единого окна в модуле LMS, прикрепив отсканированные документы (личное заявление и документ, подтверждающий льготу).\"]\n",
        "# Проверка хорошего ответа\n",
        "score = hallucination_score(context_1, model_output_1)\n",
        "print(f\"Score для хорошего ответа: {score:.4f}\")\n",
        "\n",
        "model_output_2 = \"Для продления социальной стипендии необходимо подать заявку через сервис единого окна в модуле SMART LMS, прикрепив отсканированные документы (Паспорт и водительские права).\"\n",
        "# Проверка плохого ответа\n",
        "score = hallucination_score(context_1, model_output_2)\n",
        "print(f\"Score для хорошего ответа: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPXAfJ8hMmCT",
        "outputId": "e1daa098-c107-4279-d854-46343e2fec3d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score для хорошего ответа: 0.6023\n",
            "Score для хорошего ответа: 0.3544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.translate import bleu_score\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from typing import List\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Загружаем предобученную модель для семантического сходства\n",
        "semantic_model = SentenceTransformer(\"distiluse-base-multilingual-cased\")\n",
        "\n",
        "def extract_keywords(text: str, stop_words) -> set:\n",
        "    \"\"\"Извлекает ключевые слова, исключая стоп-слова и короткие токены.\"\"\"\n",
        "    words = text.lower().split()\n",
        "    return {word for word in words if word not in stop_words and len(word) > 3}\n",
        "\n",
        "def hallucination_score(contexts: List[str], model_output: str) -> float:\n",
        "    \"\"\"Оценивает степень галлюцинации ответа модели по сравнению с контекстом.\"\"\"\n",
        "\n",
        "    stop_words = set(stopwords.words('russian'))  # Стоп-слова для русского языка\n",
        "\n",
        "    # Извлекаем ключевые слова из всех контекстов\n",
        "    context_keywords = set()\n",
        "    for context in contexts:\n",
        "        context_keywords.update(extract_keywords(context, stop_words))\n",
        "\n",
        "    # Ключевые слова из ответа модели\n",
        "    output_keywords = extract_keywords(model_output, stop_words)\n",
        "\n",
        "    # Jaccard similarity (не штрафуем, если ответ короче, но точен)\n",
        "    keyword_overlap = len(context_keywords & output_keywords) / max(len(output_keywords), 1)\n",
        "\n",
        "    # BLEU-оценка (униграммы и биграммы)\n",
        "    bleu_scores = []\n",
        "    for context in contexts:\n",
        "        try:\n",
        "            score = bleu_score.sentence_bleu(\n",
        "                references=[context.split()],\n",
        "                hypothesis=model_output.split(),\n",
        "                weights=(0.7, 0.3, 0, 0)  # Униграммы (70%) и биграммы (30%)\n",
        "            )\n",
        "            bleu_scores.append(score)\n",
        "        except ZeroDivisionError:\n",
        "            bleu_scores.append(0)\n",
        "\n",
        "    bleu_mean = np.mean(bleu_scores) if bleu_scores else 0.0\n",
        "\n",
        "    # Семантическое сходство (Sentence Transformer)\n",
        "    context_embeddings = semantic_model.encode(contexts, convert_to_tensor=True)\n",
        "    output_embedding = semantic_model.encode(model_output, convert_to_tensor=True)\n",
        "\n",
        "    semantic_similarity = util.cos_sim(output_embedding, context_embeddings).max().item()  # Берем максимальное сходство\n",
        "\n",
        "    # Штраф за неожиданные слова (учитываем редкость)\n",
        "    unexpected_words = output_keywords - context_keywords\n",
        "    unexpected_penalty = min(len(unexpected_words) / (len(output_keywords) + 1e-6), 1.0)\n",
        "\n",
        "    # Итоговый коэффициент (BLEU + семантика + пересечение - штраф)\n",
        "    final_score = (0.3 * semantic_similarity + 0.55 * bleu_mean + 0.15 * keyword_overlap) * (1 - unexpected_penalty)\n",
        "\n",
        "    return max(final_score, 0)  # Исключаем отрицательные значения\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAJSdCceIWst",
        "outputId": "57a46636-f3bd-4f87-bdae-6c9a61d5ad57"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования\n",
        "if __name__ == \"__main__\":\n",
        "    # Пример данных\n",
        "    contexts = [\n",
        "        \"Для оформления материальной помощи на оплату общежития необходимо предоставить определенные медицинские документы, такие как справка по форме 086у или сертификат МОДФ.\",\n",
        "        \"Также нужно учесть, что условия предоставления мест и размещения в общежитиях различаются.\"\n",
        "         \"Более подробную информацию можно получить в Дирекции по управлению общежитиями, гостиницами, учебно-оздоровительными комплексами.\"\n",
        "    ]\n",
        "    model_output_good = \"Для оформления материальной помощи на оплату общежития необходимо предоставить определенные медицинские документы\"\n",
        "    model_output_bad = \"Интернет изобрел Илон Маск в 2010 году в гараже.\"\n",
        "\n",
        "    # Проверка хорошего ответа\n",
        "    good_score = hallucination_score(contexts, model_output_good)\n",
        "    print(f\"Score для хорошего ответа: {good_score:.4f}\")\n",
        "\n",
        "    # Проверка плохого (галлюцинирующего) ответа\n",
        "    bad_score = hallucination_score(contexts, model_output_bad)\n",
        "    print(f\"Score для плохого ответа: {bad_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itBZ3Eat7osB",
        "outputId": "cbdac685-84c7-4fbe-97b5-6f9067d8727b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score для хорошего ответа: 0.4406\n",
            "Score для плохого ответа: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number 3.\n",
        "# Пример 1\n",
        "model_output_1 = \"Для продления социальной стипендии необходимо подать заявку через сервис единого окна в модуле LMS, прикрепив отсканированные документы (личное заявление и документ, подтверждающий льготу).\"\n",
        "context_1 = [\"Дополнительные документы для продления социальной стипендии нужно предоставить в Центр стипендиальных и благотворительных программ НИУ ВШЭ. Это включает копию заявления и копию действующей справки МСЭ. Для продления социальной стипендии необходимо подать заявку через сервис единого окна в модуле LMS, прикрепив отсканированные документы (личное заявление и документ, подтверждающий льготу).\"]\n",
        "# Проверка хорошего ответа\n",
        "score = hallucination_score(context_1, model_output_1)\n",
        "print(f\"Score для хорошего ответа: {score:.4f}\")\n",
        "\n",
        "model_output_2 = \"Для продления социальной стипендии необходимо подать заявку через сервис единого окна в модуле SMART LMS, прикрепив отсканированные документы (Паспорт и водительские права).\"\n",
        "# Проверка плохого ответа\n",
        "score = hallucination_score(context_1, model_output_2)\n",
        "print(f\"Score для хорошего ответа: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNBTX_MxEhg8",
        "outputId": "a1bfa31b-01e5-4023-9ed4-03eb084bc775"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score для хорошего ответа: 0.6023\n",
            "Score для хорошего ответа: 0.3544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_W4DrzZ5iK0"
      },
      "source": [
        "4. Проверка противоречий между контекстами и ответом\n",
        "Идея: Если model_output противоречит хотя бы одному из contexts (например, разные даты или имена), это признак галлюцинации. Можно использовать простую эвристику или более сложные методы (например, NLI)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnnIpFm-7vam",
        "outputId": "06e3aca2-d159-4bde-d827-6f42a192cb0e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ru-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.7.0/ru_core_news_sm-3.7.0-py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from ru-core-news-sm==3.7.0) (3.7.5)\n",
            "Collecting pymorphy3>=1.0.0 (from ru-core-news-sm==3.7.0)\n",
            "  Downloading pymorphy3-2.0.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting dawg2-python>=0.8.0 (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0)\n",
            "  Downloading dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.1.2)\n",
            "Downloading pymorphy3-2.0.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymorphy3-dicts-ru, dawg2-python, pymorphy3, ru-core-news-sm\n",
            "Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.3 pymorphy3-dicts-ru-2.4.417150.4580142 ru-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download ru_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9VG31WZA7dJ-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "class FactVerificationScore:\n",
        "    def __init__(self):\n",
        "        self.sent_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "        self.gpt_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "        self.nlp = spacy.load(\"ru_core_news_sm\")  # Для русского языка\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.gpt_model.eval()\n",
        "        self.gpt_model.to(self.device)\n",
        "\n",
        "    def _encode_text(self, text):\n",
        "        return self.sent_model.encode(text, convert_to_tensor=True, device=self.device)\n",
        "\n",
        "    def _extract_facts(self, text):\n",
        "        doc = self.nlp(text)\n",
        "        entities = set(ent.text for ent in doc.ents)\n",
        "        entities.update(re.findall(r'\\b\\d{4}\\b|\\b[А-ЯA-Z][а-яa-z]+(?: [А-ЯA-Z][а-яa-z]+)*', text))\n",
        "        return entities\n",
        "\n",
        "    def _calculate_perplexity(self, text):\n",
        "        inputs = self.gpt_tokenizer(text, return_tensors=\"pt\").to(self.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.gpt_model(**inputs, labels=inputs[\"input_ids\"])\n",
        "            loss = outputs.loss\n",
        "            perplexity = torch.exp(loss).item()\n",
        "        return perplexity\n",
        "\n",
        "    def _detect_negation(self, context):\n",
        "        \"\"\" Проверяет, есть ли явное отрицание в контексте \"\"\"\n",
        "        negation_patterns = [\n",
        "            r\"информация.*отсутствует\",\n",
        "            r\"не указано\",\n",
        "            r\"нет данных\",\n",
        "            r\"невозможно\"\n",
        "        ]\n",
        "        return any(re.search(pattern, context.lower()) for pattern in negation_patterns)\n",
        "\n",
        "    def calculate_score(self, model_output, context):\n",
        "        # Концептуальная согласованность\n",
        "        concept_score = util.cos_sim(self._encode_text(model_output), self._encode_text(context)).item()\n",
        "\n",
        "        # Перплексия\n",
        "        perplexity = self._calculate_perplexity(model_output)\n",
        "        normalized_perplexity = min(1.0, perplexity / 50.0)\n",
        "\n",
        "        # Фактологическая проверка\n",
        "        model_facts = self._extract_facts(model_output)\n",
        "        context_facts = self._extract_facts(context)\n",
        "        hallucinated_facts = len(model_facts - context_facts)  # Новые факты, не из контекста\n",
        "        missing_facts = len(context_facts - model_facts)       # Пропущенные факты из контекста\n",
        "        fact_error_ratio = hallucinated_facts / max(1, len(model_facts))\n",
        "        missing_fact_ratio = missing_facts / max(1, len(context_facts))\n",
        "\n",
        "        # Проверка на явное отрицание в контексте\n",
        "        negation_detected = self._detect_negation(context)\n",
        "        negation_penalty = 1.0 if (negation_detected and hallucinated_facts > 0) else 0.0\n",
        "\n",
        "        # Итоговый скор\n",
        "        w_concept = 0.35       # Концептуальная согласованность\n",
        "        w_perplexity = 0.15    # Перплексия (меньший вес, так как она менее значима)\n",
        "        w_fact_error = 0.35    # Ошибки фактов\n",
        "        w_missing = 0.15       # Пропущенные факты\n",
        "        hallucination_score = (\n",
        "            w_concept * (1 - concept_score) +\n",
        "            w_perplexity * normalized_perplexity +\n",
        "            w_fact_error * fact_error_ratio +\n",
        "            w_missing * missing_fact_ratio +\n",
        "            negation_penalty * 0.5  # Дополнительный штраф за противоречие отрицанию\n",
        "        )\n",
        "        hallucination_score = min(1, max(0, hallucination_score))\n",
        "\n",
        "        return {\n",
        "            \"hallucination_score\": hallucination_score,\n",
        "            \"concept_score\": concept_score,\n",
        "            \"perplexity\": perplexity,\n",
        "            \"fact_error_ratio\": fact_error_ratio,\n",
        "            \"missing_fact_ratio\": missing_fact_ratio,\n",
        "            \"hallucinated_facts\": hallucinated_facts,\n",
        "            \"missing_facts\": missing_facts,\n",
        "            \"negation_detected\": negation_detected\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Тестирование\n",
        "verifier = FactVerificationScore()\n",
        "\n",
        "# Пример 1\n",
        "model_output_1 = \"Для продления социальной стипендии необходимо подать заявку через сервис единого окна в модуле LMS, прикрепив отсканированные документы (личное заявление и документ, подтверждающий льготу).\"\n",
        "context_1 = \"Дополнительные документы для продления социальной стипендии нужно предоставить в Центр стипендиальных и благотворительных программ НИУ ВШЭ. Это включает копию заявления и копию действующей справки МСЭ. Для продления социальной стипендии необходимо подать заявку через сервис единого окна в модуле LMS, прикрепив отсканированные документы (личное заявление и документ, подтверждающий льготу).\"\n",
        "result_1 = verifier.calculate_score(model_output_1, context_1)\n",
        "print(\"Пример 1:\", result_1)\n",
        "\n",
        "# Пример 2\n",
        "model_output_2 = \"Получение автомата возможно, если студент выполняет все необходимые требования и проходит защиту ВКР успешно.\"\n",
        "context_2 = \"Информация о возможности получения автомата в данном тексте отсутствует.\"\n",
        "result_2 = verifier.calculate_score(model_output_2, context_2)\n",
        "print(\"Пример 2:\", result_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTuRdcQ98Icf",
        "outputId": "f588ab39-5801-4ed6-a6e3-d9b4df0aebd1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример 1: {'hallucination_score': 0.28958986440726686, 'concept_score': 0.6217824816703796, 'perplexity': 9.54743480682373, 'fact_error_ratio': 0.0, 'missing_fact_ratio': 0.8571428571428571, 'hallucinated_facts': 0, 'missing_facts': 6, 'negation_detected': False}\n",
            "Пример 2: {'hallucination_score': 1, 'concept_score': 0.7931008338928223, 'perplexity': 8.530292510986328, 'fact_error_ratio': 1.0, 'missing_fact_ratio': 1.0, 'hallucinated_facts': 2, 'missing_facts': 1, 'negation_detected': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verifier = FactVerificationScore()\n",
        "\n",
        "# Пример 1\n",
        "model_output_1 = \"Для продления социальной стипендии необходимо подать заявку через сервис единого окна в модуле LMS, прикрепив отсканированные документы (личное заявление и документ, подтверждающий льготу).\"\n",
        "context_1 = \"Дополнительные документы для продления социальной стипендии нужно предоставить в Центр стипендиальных и благотворительных программ НИУ ВШЭ. Это включает копию заявления и копию действующей справки МСЭ. Для продления социальной стипендии необходимо подать заявку через сервис единого окна в модуле LMS, прикрепив отсканированные документы (личное заявление и документ, подтверждающий льготу).\"\n",
        "result_1 = verifier.calculate_score(model_output_1, context_1)\n",
        "print(\"Пример 1:\", result_1)\n",
        "\n",
        "model_output__2 = \"Для оформления материальной помощи на оплату общежития необходимо предоставить определенные медицинские документы\"\n",
        "context_2 = \"Для оформления материальной помощи на оплату общежития необходимо предоставить определенные медицинские документы, такие как справка по форме 086у или сертификат МОДФ.\\\n",
        "Также нужно учесть, что условия предоставления мест и размещения в общежитиях различаются.\\\n",
        "Более подробную информацию можно получить в Дирекции по управлению общежитиями, гостиницами, учебно-оздоровительными комплексами.\"\n",
        "result_2 = verifier.calculate_score(model_output_2, context_2)\n",
        "print(\"Пример 1:\", result_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr6Q2hJjB9dQ",
        "outputId": "7ee0e43e-e6d6-4606-87d1-b1250564f31a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример 1: {'hallucination_score': 0.28958986440726686, 'concept_score': 0.6217824816703796, 'perplexity': 9.54743480682373, 'fact_error_ratio': 0.0, 'missing_fact_ratio': 0.8571428571428571, 'hallucinated_facts': 0, 'missing_facts': 6, 'negation_detected': False}\n",
            "Пример 1: {'hallucination_score': 0.7097788798809052, 'concept_score': 0.4737485647201538, 'perplexity': 8.530292510986328, 'fact_error_ratio': 1.0, 'missing_fact_ratio': 1.0, 'hallucinated_facts': 2, 'missing_facts': 6, 'negation_detected': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7T8-Wl48wE1"
      },
      "source": [
        "# Математическая модель метрики FactVerificationScore\n",
        "\n",
        "## Обозначения\n",
        "Пусть:\n",
        "- $O$ — текст ответа модели (`model_output`),\n",
        "- $C$ — текст контекста (`context`),\n",
        "- $S_{\\text{concept}}(O, C)$ — концептуальная согласованность (косинусное сходство между $O$ и $C$),\n",
        "- $P(O)$ — перплексия текста $O$,\n",
        "- $F_O$ — множество фактов, извлечённых из $O$,\n",
        "- $F_C$ — множество фактов, извлечённых из $C$,\n",
        "- $H = |F_O \\setminus F_C|$ — число \"галлюцинированных\" фактов,\n",
        "- $M = |F_C \\setminus F_O|$ — число \"пропущенных\" фактов,\n",
        "- $R_{\\text{fact}}$ — доля ошибочных (галлюцинированных) фактов,\n",
        "- $R_{\\text{missing}}$ — доля пропущенных фактов,\n",
        "- $N(C)$ — индикатор наличия отрицания в контексте ($1$, если есть; $0$, если нет),\n",
        "- $P_N$ — штраф за противоречие отрицанию,\n",
        "- $w_{\\text{concept}}, w_{\\text{perplexity}}, w_{\\text{fact}}, w_{\\text{missing}}$ — весовые коэффициенты,\n",
        "- $H_{\\text{score}}$ — итоговый показатель галлюцинации.\n",
        "\n",
        "## Компоненты метрики\n",
        "\n",
        "### Концептуальная согласованность\n",
        "Концептуальная согласованность:\n",
        "$$ S_{\\text{concept}}(O, C) = \\cos(\\text{Emb}(O), \\text{Emb}(C)), $$\n",
        "где $\\text{Emb}(O)$ и $\\text{Emb}(C)$ — векторные представления, полученные через `SentenceTransformer`.  \n",
        "Для метрики используется:\n",
        "$$ 1 - S_{\\text{concept}}(O, C). $$\n",
        "\n",
        "### Нормализованная перплексия\n",
        "Перплексия:\n",
        "$$ P(O) = e^{L(O)}, $$\n",
        "где $L(O)$ — кросс-энтропийная потеря модели GPT-2. Нормализованная перплексия:\n",
        "$$ P_{\\text{norm}}(O) = \\min\\left(1, \\frac{P(O)}{50}\\right). $$\n",
        "\n",
        "### Фактологическая проверка\n",
        "- Число галлюцинированных фактов: $H = |F_O \\setminus F_C|$,\n",
        "- Число пропущенных фактов: $M = |F_C \\setminus F_O|$,\n",
        "- Доля ошибочных фактов:\n",
        "$$ R_{\\text{fact}} = \\frac{H}{\\max(1, |F_O|)}, $$\n",
        "- Доля пропущенных фактов:\n",
        "$$ R_{\\text{missing}} = \\frac{M}{\\max(1, |F_C|)}. $$\n",
        "\n",
        "### Штраф за отрицание\n",
        "Индикатор отрицания:\n",
        "$$ N(C) = \\begin{cases}\n",
        "1, & \\text{если в } C \\text{ найдено отрицание}, \\\\\n",
        "0, & \\text{иначе}.\n",
        "\\end{cases} $$\n",
        "Штраф:\n",
        "$$ P_N = \\begin{cases}\n",
        "1, & \\text{если } N(C) = 1 \\text{ и } H > 0, \\\\\n",
        "0, & \\text{иначе}.\n",
        "\\end{cases} $$\n",
        "Вклад штрафа:\n",
        "$$ \\text{Negation Penalty} = P_N \\cdot 0.5. $$\n",
        "\n",
        "### Итоговый показатель\n",
        "$$ H_{\\text{score}} = \\min\\left(1, \\max\\left(0, w_{\\text{concept}} \\cdot (1 - S_{\\text{concept}}) + w_{\\text{perplexity}} \\cdot P_{\\text{norm}} + w_{\\text{fact}} \\cdot R_{\\text{fact}} + w_{\\text{missing}} \\cdot R_{\\text{missing}} + 0.5 \\cdot P_N\\right)\\right), $$\n",
        "где:\n",
        "- $w_{\\text{concept}} = 0.35$,\n",
        "- $w_{\\text{perplexity}} = 0.15$,\n",
        "- $w_{\\text{fact}} = 0.35$,\n",
        "- $w_{\\text{missing}} = 0.15$.\n",
        "\n",
        "## Полная модель\n",
        "$$ H_{\\text{score}} = \\min\\left(1, \\max\\left(0, 0.35 \\cdot (1 - \\cos(\\text{Emb}(O), \\text{Emb}(C))) + 0.15 \\cdot \\min\\left(1, \\frac{e^{L(O)}}{50}\\right) + 0.35 \\cdot \\frac{|F_O \\setminus F_C|}{\\max(1, |F_O|)} + 0.15 \\cdot \\frac{|F_C \\setminus F_O|}{\\max(1, |F_C|)} + 0.5 \\cdot P_N\\right)\\right). $$\n",
        "\n",
        "## Интерпретация\n",
        "- $H_{\\text{score}} \\approx 0$: ответ полностью соответствует контексту.\n",
        "- $H_{\\text{score}} \\approx 1$: ответ содержит значительные галлюцинации или противоречия.\n",
        "\n",
        "## Пример применения\n",
        "\n",
        "### Пример 1\n",
        "- $S_{\\text{concept}} \\approx 0.98$,\n",
        "- $P(O) \\approx 12.34$, $P_{\\text{norm}} = 0.247$,\n",
        "- $H = 0$, $R_{\\text{fact}} = 0$,\n",
        "- $M = 3$, $|F_C| = 5$, $R_{\\text{missing}} = 0.6$,\n",
        "- $N(C) = 0$, $P_N = 0$.\n",
        "\n",
        "$$ H_{\\text{score}} = 0.35 \\cdot 0.02 + 0.15 \\cdot 0.247 + 0.35 \\cdot 0 + 0.15 \\cdot 0.6 = 0.134. $$\n",
        "\n",
        "### Пример 2\n",
        "- $S_{\\text{concept}} \\approx 0.45$,\n",
        "- $P(O) \\approx 15.67$, $P_{\\text{norm}} = 0.313$,\n",
        "- $H = 2$, $|F_O| = 2$, $R_{\\text{fact}} = 1.0$,\n",
        "- $M = 0$, $R_{\\text{missing}} = 0$,\n",
        "- $N(C) = 1$, $P_N = 1$.\n",
        "\n",
        "$$ H_{\\text{score}} = 0.35 \\cdot 0.55 + 0.15 \\cdot 0.313 + 0.35 \\cdot 1.0 + 0.15 \\cdot 0 + 0.5 \\cdot 1 = 1.0895, $$\n",
        "$$ H_{\\text{score}} = \\min(1, 1.0895) = 1. $$"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}