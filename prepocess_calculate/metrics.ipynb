{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class ConceptualCoherenceScore:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "        self.model = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.model.eval()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def _encode_text(self, text):\n",
    "        inputs = self.tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**{k: v.to(self.device) for k, v in inputs.items()})\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        return embeddings\n",
    "\n",
    "    def calculate_score(self, model_output, ground_truth, context):\n",
    "        # 1. Вычисление языкового соответствия (как в BertScore)\n",
    "        model_embeddings = self._encode_text(model_output)\n",
    "        gt_embeddings = self._encode_text(ground_truth)\n",
    "        language_score = cosine_similarity(model_embeddings, gt_embeddings)[0][0]\n",
    "\n",
    "        # 2. Вычисление концептуальной согласованности\n",
    "        context_embeddings = self._encode_text(context)\n",
    "        concept_score = cosine_similarity(model_embeddings, context_embeddings)[0][0]\n",
    "\n",
    "        # 3. Весовые коэффициенты\n",
    "        w_language = 0.6  # больший вес для языкового соответствия\n",
    "        w_concept = 0.4   # меньший вес для концептуальной согласованности\n",
    "\n",
    "        # 4. Итоговая метрика\n",
    "        final_score = (w_language * language_score) + (w_concept * concept_score)\n",
    "\n",
    "        return {\n",
    "            \"final_score\": final_score,\n",
    "            \"language_score\": language_score,\n",
    "            \"concept_score\": concept_score\n",
    "        }\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    evaluator = ConceptualCoherenceScore()\n",
    "\n",
    "    model_output = \"ВШЭ - это крупнейший университет России, основанный в 1990 году\"\n",
    "    ground_truth = \"ВШЭ - это национальный исследовательский университет, основанный в 1992 году\"\n",
    "    context = [\n",
    "        \"НИУ ВШЭ был основан в 1992 году\",\n",
    "        \"Высшая школа экономики является одним из ведущих университетов России\",\n",
    "        \"В 1992 году была создана Высшая школа экономики\"\n",
    "    ]\n",
    "\n",
    "    result = evaluator.calculate_score(model_output, ground_truth, context)\n",
    "    print(f\"Итоговая метрика: {result['final_score']}\")\n",
    "    print(f\"Языковое соответствие: {result['language_score']}\")\n",
    "    print(f\"Концептуальная согласованность: {result['concept_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта реализация включает:\n",
    "- Вычисление языкового соответствия между выходом модели и ground truth\n",
    "- Оценку концептуальной согласованности с контекстом\n",
    "- Взвешенное объединение метрик\n",
    "- Детальную разбивку результатов\n",
    "\n",
    "Особенности:\n",
    "- Использует BERT для получения эмбеддингов\n",
    "- Вычисляет косинусное сходство\n",
    "- Учитывает как языковое соответствие, так и концептуальную согласованность\n",
    "- Предоставляет детальный отчет по каждой метрике\n",
    "\n",
    "При неверной интерпретации ключевых концептов (например, неверной дате основания ВШЭ), метрика концептуальной согласованности будет низкой, даже если языковое соответствие высокое. Это позволит выявить проблемные случаи, когда модель генерирует убедительные, но неверные ответы."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
